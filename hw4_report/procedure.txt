grep -v " 0 " wc_boilerpipe | awk4 | grep -o "\./tweets/[0-9]\+/" > boilerpipe_success_dirs

mkdir tweets2

for i in $(cat boilerpipe_success_dirs); do id=$(echo $i | grep -o "[0-9]\+"); mkdir tweets2/$id; cp "${i}url.0" tweets2/$id/url.0; done

# edit this script to use new directory and download2.stats
vim dereference_URIs.py

jtate@sirius:~/cs751/hw$ ./dereference_URIs.py
started: 3035  succeeded: 2889  header errors: 26  content errors: 120  elapsed seconds: 136

find ./tweets2/ > tweets2_file_list

./run_boilerpipe.py

wc tweets2/*/*/boilerpipe.output | tee wc_boilerpipe2

grep -v "^ \+0 " wc_boilerpipe | grep -v " total$" | awk4 | grep -o "56[0-9]\+" > boilerpipe1_ids
grep -v "^ \+0 " wc_boilerpipe2 | grep -v " total$" | awk4 | grep -o "56[0-9]\+" > boilerpipe2_ids

comm -12 <(sort boilerpipe1_ids) <(sort boilerpipe2_ids) > boilerpipe_common_ids

./jaccard.py | tee hw4_report/stats/q1_distances.stats
awk2 q1_distances.stats | tail -n +2 | sort -n > q1_unigrams.stats
awk3 q1_distances.stats | tail -n +2 | sort -n > q1_bigrams.stats
awk4 q1_distances.stats | tail -n +2 | sort -n > q1_trigrams.stats

#Q2:
./get_timemaps.py > get_timemap_output

#I had to go back and separately download the timemaps for 20 mementos that did not download properly
#due to bad final URI in tweets.summary.json. not gonna put this part in report because it would take
# forever to explain

# Get list of all mementos for timemaps
grep "\.timemap$" tweets2_file_list | xargs grep memento | grep -v rel=\"timemap\" | grep -v rel=\"timegate\" | grep -v rel=\"self\" | less | tee memento_list

./count_mementos.py > memento_counts
for i in $(seq -f "%04g" 1 1715); do echo "padding_$i 0"; done >> memento_counts
awk2 memento_counts | sort -n > hw4_report/stats/memento_counts.stats

./count_mementos.py | sort -nrk 2 | awk '{if ($2 > 19) print $1}' > twenty-plus_mementos
./identify_old_uris.py

# find old URIs that also have 20+ mementos
comm -12 <(sort two-year-old_ids) <(sort twenty-plus_mementos) > old_with_20_ids
# select 20 with fewest mementos >= 20
for i in $(cat old_with_20_ids); do grep $i memento_counts ; done | sort -nk 2 | head -20 > hw4_q3_ids
# add age column to that list
paste hw4_q3_ids <(while read line; do id=$(echo "$line" | awk1); age=$(grep -Po "${id}.*?timeDelta\": [0-9\.]+" tweets.summary.json | awknf); echo "$age"; done < hw4_q3_ids) -d' ' > tmp
mv tmp hw4_q3_ids

for i in $(awk1 hw4_q3_ids); do grep memento tweets2/$i/timemaps/*.timemap; done | grep -v rel=\"timegate | grep -v rel=\"self | grep -v rel=\"timemap > hw4_q3_mementos

./get_mementos.py hw4_q3_mementos | tee get_mementos_output

find ./tweets2/ > tweets2_file_list
for i in $(cat tweets2_file_list | grep /mementos/); do python -m justext -s English -o "$i.boilerpipe" "$i"; done
find ./tweets2/ > tweets2_file_list
grep "/mementos/.*.boilerpipe" tweets2_file_list | xargs wc > hw4_q3_wc

